{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A - Explore Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading File\n",
    "data_frame = pd.read_csv(r'C:\\Users\\stesa\\Desktop\\GoMyCode\\Titanic_Survived.csv')\n",
    "\n",
    "#Display data\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Length\n",
    "data_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output counts\n",
    "data_frame['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot 'Survived'\n",
    "sns.countplot(x =data_frame.Survived,order=data_frame['Survived'].value_counts().index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot 'Survived' with 'Pclass'\n",
    "sns.countplot(x='Survived', hue='Pclass', data=data_frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Plot 'Survived' with 'male'\n",
    "sns.countplot(x='Survived', hue='male', data=data_frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot 'Survived' with 'FamilySize'\n",
    "sns.countplot(x='Survived', hue='FamilySize', data=data_frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B - Supervised Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####      A- Splitting dataset into a training set and a testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features extraction\n",
    "\n",
    "x = data_frame.drop('Survived' , axis=1)\n",
    "y = data_frame['Survived']\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=20) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####      B- Feature Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc_x = StandardScaler()\n",
    "x_train = sc_x.fit_transform(x_train)\n",
    "x_test = sc_x.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####      C- Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='newton-cg') #build Logistic regression model\n",
    "model.fit(x_train,y_train) #fitting the training data\n",
    "pred=model.predict(x_test) #testing our model’s performance\n",
    "y_pred_logistic = model.decision_function(x_test)\n",
    "\n",
    "print(classification_report(y_test,pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####      D- Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix = pd.crosstab(y_test, pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "sns.heatmap(confusion_matrix, annot=True)\n",
    "print(confusion_matrix)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC / AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score \n",
    "\n",
    "logistic_fpr, logistic_tpr, threshold = roc_curve(y_test, y_pred_logistic)\n",
    "auc_logistic = auc(logistic_fpr,logistic_tpr)\n",
    "\n",
    "plt.figure(figsize=(10,5), dpi=60)\n",
    "plt.plot(logistic_fpr, logistic_tpr, marker='.', label='Logistic (auc = %0.3f)' % auc_logistic)\n",
    "plt.xlabel('False Positive Rate -->')\n",
    "plt.ylabel('True Positive Rate -->')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "auc = np.round(roc_auc_score(y_test, pred), 3) \n",
    "print('Default Area Under Cuve : Threshold = 0.5')\n",
    "print(\"Auc for our data is {}\". format(auc))\n",
    "print('Auc after using ROC_Curve is 0.864')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####      A- Splitting dataset into a training set and a testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features extraction\n",
    "\n",
    "features = ['Pclass','Fare','FamilySize','C','Q','S','female','male','Age']\n",
    "x = data_frame[features]\n",
    "y = data_frame['Survived']\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=20) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####      B- Feature Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc_x = StandardScaler()\n",
    "x_train = sc_x.fit_transform(x_train)\n",
    "x_test = sc_x.fit_transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####     C- Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='newton-cg') #build Logistic regression model\n",
    "model.fit(x_train,y_train) #fitting the training data\n",
    "pred=model.predict(x_test) #testing our model’s performance\n",
    "y_pred_logistic = model.decision_function(x_test)\n",
    "\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####      D- Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix = pd.crosstab(y_test, pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "sns.heatmap(confusion_matrix, annot=True)\n",
    "print(confusion_matrix)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC / AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score \n",
    "\n",
    "logistic_fpr, logistic_tpr, threshold = roc_curve(y_test, y_pred_logistic)\n",
    "auc_logistic = auc(logistic_fpr,logistic_tpr)\n",
    "\n",
    "plt.figure(figsize=(10, 5), dpi=60)\n",
    "plt.plot(logistic_fpr, logistic_tpr, marker='.', label='Logistic (auc = %0.3f)' % auc_logistic)\n",
    "plt.xlabel('False Positive Rate -->')\n",
    "plt.ylabel('True Positive Rate -->')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "auc = np.round(roc_auc_score(y_test, pred), 3) \n",
    "print('Default Area Under Cuve : Threshold = 0.5')\n",
    "print('Auc For our Data is {}'. format(auc))\n",
    "print('Auc after using ROC_Curve is 0.860')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC_AUC Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Receiver Operating Characteristics (ROC) :\n",
    "\n",
    "#Curve is constructed by plotting the true positive rate (TPR) against the false positive rate (FPR).\n",
    "#Classifiers that give curves closer to the top-left corner indicate a better performance.\n",
    "#The closer the curve comes to the 45-degree diagonal of the ROC space, the less accurate the test.\n",
    "\n",
    "## The Area Under the Curve (AUC)\n",
    "\n",
    "#Auc is the measure of the ability of a classifier to distinguish between classes and is used as a summary of the ROC curve\n",
    "#An excellent model has AUC near to the 1 which means it has a good measure of separability. \n",
    "#A poor model has AUC near to the 0 which means it has the worst measure of separability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
